Master Collation Guide for Deterministic Laboratory and Diagnostic Reference Datasets — Context-Aligned to esoa_prepared_labs.csv

Overview of Observed Test Categories in esoa_prepared_labs.csv

The uploaded dataset of Electronic Statement of Account (ESOA) entries reveals a wide spectrum of laboratory tests, imaging procedures, and related services. By inspecting the DESCRIPTION field, we can group the entries into several high-level clusters:
	•	Clinical Chemistry – e.g. glucose tests (Fasting Blood Sugar), electrolytes (“SODIUM SERUM”, “POTASSIUM SERUM”, “ELECTROLYTES (NA+, K+, CA++, CL-)”), liver and renal function markers (creatinine, BUN, “BILIRUBIN, TOTAL/DIRECT/INDIRECT” ￼, enzymes like SGPT/ALT, SGOT/AST). Lipids are present as “LIPID PROFILE” and components (“CHOLESTEROL”, “TRIGLYCERIDES (TAG)” ￼). We also see glucose tolerance tests (“OGTT 75g 2h” format in local terms) and HbA1c (though not explicitly shown above, likely present). Units sometimes appear in descriptions (e.g. “RANDOM BLOOD SUGAR – 85 MG/DL” ￼), indicating embedded result values.
	•	Hematology – e.g. complete blood count (“CBC” in “LAB-HMT- CBC” ￼), hemoglobin/hematocrit (“HCT” ￼), coagulation tests (“PROTHROMBIN TIME (PT/PTPA/INR)” ￼), erythrocyte sedimentation rate (“ERYTHROCYTE SEDIMENTATION RATE (ESR)” ￼). Blood cell counts and differentials are present, sometimes as panels (CBC with platelet count). Blood banking/immunohematology appears with blood typing (“BLOOD TYPE (ABO+RH)” ￼), crossmatching (“CROSS MATCHING (MAJOR) – GEL TECHNIQUE” ￼), direct Coomb’s tests ￼, etc. Blood products and transfusion services are listed as well (e.g. “PACKED RBC BLOOD TYPE ‘A’ RH POSITIVE” ￼, platelet concentrate, FFP).
	•	Immunology/Serology – e.g. infectious disease markers and autoimmune tests. The dataset contains viral hepatitis markers like “ANTI-HBs (QUANTI)” ￼, “ANTI-HBc IgM/IgG” ￼, “HBsAg” (possibly in “ACUTE HEPATITIS PROFILE (HBsAg, HAVM, HCV)” ￼), and HIV (“HUMAN IMMUNODEFICIENCY VIRUS HIV 1/2” ￼). Dengue tests appear (“DENGUE COMBO (NS1, IgM, IgG) – RAPID” ￼ and “DENGUE DOT (QUALITATIVE)” ￼). Other serologies include Typhoid (“TYPHIDOT, RAPID” ￼), H. pylori (“H.PYLORI, RAPID” ￼), Syphilis (likely RPR), RF (rheumatoid factor), CRP (“C-REACTIVE PROTEIN” ￼) and ANA (“ANA W/ TITER” ￼). Many are labeled as rapid or kit tests. Endocrine immunoassays like TSH, FT3, FT4 (“FT3 (FREE TRIIODOTHYRONINE)” ￼) and hormone/tumor markers (beta-hCG, PSA in “ECU – PROSTATE SPECIFIC ANTIGEN” ￼, “TROPONIN I (QUALITATIVE)” ￼) are present.
	•	Microbiology – e.g. culture and sensitivity tests for various specimen types: urine (“URINE GRAM STAIN & CULTURE SENSITIVITY” ￼), blood (“BLOOD CULTURES & SENSITIVITY” ￼; multiple sites), sputum ￼, wound exudates ￼, tracheal aspirate ￼, “CULTURE & SENSITIVITY (URINE, SPUTUM, ETC.)” ￼. There are stains like Gram stain ￼ and Acid-Fast Bacilli (AFB) smear (“ACID FAST BACILLI STAIN (AFB STAIN)” ￼, “AFB DIRECT SMEAR” ￼). Parasitology appears (e.g. “KATO-KATZ FOR SCHISTO” for stool parasites ￼, “Malarial Smear” ￼, possibly O&P exam as part of Fecalysis). Fungal prep like KOH (“POTASSIUM HYDROXIDE (KOH)” ￼) is present. Organism identification is not by name in the test list (organisms would be results), but tests imply coverage of bacterial, mycobacterial, parasitic, and fungal diagnostics.
	•	Urinalysis & Fecalysis – Routine fluid exams are clearly present: “URINALYSIS” (with variants “URINALYSIS WITH COMBILYZER” ￼, automated vs manual ￼) and “FECALYSIS” (stool analysis, listed as “ECU – FECALYSIS” ￼ and a general entry ￼). These often appear as part of panels (e.g. executive check-ups). There are also specialized urine tests like “URINE CYTOMETRY (10 parameters)” ￼, “Urine protein & creatinine ratio” ￼, and “24H Urine Creatinine Clearance” ￼, indicating timed collections.
	•	Endocrine and Hormones – Aside from thyroid hormones and cortisol, we have tests like HbA1c (implied by “CKD – CBC” possibly a chronic disease panel, or separate code), cortisol (present in “ANTI-HBS – CORTISOL” combined entry ￼), ACTH (not explicitly seen, but likely in dataset), reproductive hormones (not shown above but possibly “FSH, LH, Estradiol” could exist), vitamin D or others (not confirmed). Glucose tolerance tests are present (“ORAL GLUCOSE TOLERANCE TEST (75g)” ￼ and “2 HOUR POST PRANDIAL TEST” ￼). The presence of “ANTI-HBS – … OSMOLALITY” entries ￼ suggests some combined or sequential tests in an endocrine context (perhaps part of a water deprivation test or diabetes insipidus workup with serum/urine osmolality at different times).
	•	Blood Banking & Transfusion – The data includes ABO/Rh typing (“BLOOD TYPE (ABO+RH)” ￼), antibody screen (“TYPE & SCREEN” ￼), crossmatching (major/minor, with gel method ￼), direct anti-globulin tests (Coomb’s test ￼). Blood product administration entries exist (e.g. “BLOOD TRANSFUSION – PACKED RBC” ￼) and various blood product items (“CRYOPRECIPITATE, ANY BLOOD TYPE” ￼, “FRESH FROZEN PLASMA, ANY BLOOD TYPE” ￼, platelet concentrate, etc.), which are not lab tests per se but appear in the billing dataset under diagnostics.
	•	Molecular Tests (PCR-based) – We see evidence of molecular diagnostics: “GENE EXPERT (PLEURAL)” ￼ (GeneXpert PCR for TB in pleural fluid), possibly “COVID-19 RAPID ANTIGEN” and likely a PCR entry not shown but expected (the dataset was updated through 2025, so “COVID-19 PCR” might be present). Also “TB QUANTIFERON (SEND OUT)” ￼ (an IFN-γ release assay), and possibly other PCR tests for infectious diseases. The term “PCR” is likely embedded in some entries (e.g., “PCR – [target]”), though not explicitly shown in snippet.
	•	Imaging and Diagnostic Procedures – Many imaging procedures are listed, indicating that Radiology and Cardiology diagnostics are included in the same item library:
	•	X-ray: Numerous X-ray exams by body part and view (e.g. “CHEST X-RAY (PA/APL)” ￼, “LEFT ANKE APL” – likely “ankle AP/Lateral” ￼, “HAND APL” (AP and lateral) ￼, “FOOT APO” (AP/oblique) ￼, “Extremities – leg, thigh” etc.). Portable X-ray charges are separate (“CHEST AP – PORTABLE” ￼, “PORTABLE CHEST AP (ADULT)” ￼). Specialized views like “APICO-LORDOTIC VIEW” ￼ and decubitus positions ￼ are listed.
	•	Ultrasound (UTZ): Many ultrasound exams by organ/region: “Thyroids UTZ” ￼, “Pelvis UTZ” ￼, “TRANSVAGINAL UTZ” ￼, “KUB ultrasound” ￼, “Appendix (ULTRASOUND)” ￼, “Whole abdomen ultrasound” ￼, “Ultrasound guided biopsy” ￼, etc. “Portable ultrasound” fees ￼ also appear. Some are prefixed with “WC-” (possibly indicating Women’s Center), and OB/Gyn-specific ultrasounds (fetal biometry, transrectal ultrasound for prostate ￼).
	•	CT Scan: e.g. “FACIAL BONE CT SCAN” ￼, “WHOLE ABDOMEN CT SCAN WITH CONTRAST” ￼, “CT CRANIAL PLAIN” ￼, “NECK CT-SCAN W/ CONTRAST” ￼. Some have 3D reconstruction (“3D SCAN CT” ￼) or are tagged STAT (after hours fees ￼).
	•	MRI: e.g. “MRI – PROSTATE (MULTIPARAMETRIC)” ￼, “MRCP MRI – CONTRAST” ￼ (MR cholangiopancreatography), possibly others like “Brain MRI with MRA” ￼.
	•	Cardio-Pulmonary: ECG/EKG appears as procedure (“12-LEAD ECG” ￼, “ECG (NO READING)” ￼, “15-LEAD ECG (PEDIA)” ￼, Holter monitoring “24 HR AMBULATORY ECG (Holter)” ￼). 2D Echocardiography (“2-D ECHO W/ DOPPLER (ADULT)” ￼ and pediatric variants ￼) and Treadmill stress tests (not shown, but likely) are present. EEG (“ELECTROENCEPHALOGRAPHY (EEG)” ￼) and possibly EMG/NCV (not seen in snippet, but common in diagnostic lists) might appear. Arterial Blood Gas (ABG) Analysis is explicitly listed ￼.
	•	Others: We also see endoscopy support (C-ARM for ERCP fluoroscopy ￼), “CT Guided Biopsy” ￼, “Dialysis package” fees ￼, and even nursing/professional fees (on-call nursing, critical care fee ￼) which are not tests but included in the item list. Histopathology entries exist (“HISTOPATH BIOPSY Category 3” ￼, different levels, and “Frozen section” ￼, etc.), as well as cytology (“PAPs staining” ￼, “CYTOLOGY with cell block” ￼).

Local nomenclature patterns are evident. Abbreviations and shorthand are common: e.g., “UTZ” for ultrasound, “APL” (AP/Lateral X-ray views), “APO” (AP/Oblique), “ECU” (seen prefixing many test names, likely “Executive Check-Up”), “CKD – CBC” (possibly a bundle for chronic kidney disease labs), “LAB-HMT”, “LAB-CC”, “LAB-SI”, “LAB-CM” prefixes suggesting internal lab department codes (Hematology, Clinical Chemistry, Special Immunology, Clinical Microscopy). Panels are listed either explicitly (“LIPID PROFILE (CHOLESTEROL, TRIGLYCERIDE, HDL, LDL)” ￼, “Electrolytes (Na, K, Ca, Cl)” ￼) or implied by group codes (e.g., “CBC WITH PC AND BLOOD TYPING” ￼, “Executive Panel A/B/C”). Some test names include units or reference values (the RBS examples with mg/dL, or “ANTI-HBS – URINE OSMOLALITY – 8PM 6/1/25” which even contains a datetime stamp). These likely represent results or scheduling information embedded in the billing description, illustrating data quality issues for mapping.

Gaps and Unusual Entries: Several entries reflect local test names or packages that won’t directly match standard vocabulary names. For example, “ECU – Helicobacter Pylori Test” ￼ (part of a check-up package) or “Executive Panel C (Female)” ￼ represent bundled services. Similarly, Philippines-specific terms like “Fecalysis” (stool exam) and “Wet Smear” ￼ (vaginal smear) are commonly used locally but may not exist verbatim in international code systems. Distinct pricing for “Blood Typing – Ward vs Private” ￼ and others indicate that the same test can have multiple billing entries. License-restricted coding systems (like CPT for procedures) are not used in the dataset; instead, narrative descriptions are used. This necessitates mapping to standard codes post-hoc using multiple reference sources.

In summary, the dataset spans all major lab disciplines and diagnostic imaging, with significant use of local abbreviations, combined test panels, and context-specific naming. To achieve deterministic mapping of these items to standard references, we need a comprehensive suite of external datasets and ontologies that cover: the identity of lab tests (analytes, specimens, methods), panels and profiles, microbiology agents and antibiotics, imaging procedure terminology, units of measure, and even local Philippine term synonyms. We also need cross-maps and hierarchies to infer implicit information (e.g., that “Na+” in serum implies a property of substance concentration in blood, or that “fasting” in the name implies a specimen condition).

Below is the Master Collation Guide – a structured list of all recommended external resources, grouped by category, that must be collected to fully cover the observed test universe. Each resource entry includes its maintainer, scope, relevant “slots” (which aspect of a test’s definition it provides), format/access method, usage license, and a note on how it will map our local data and any coverage considerations or gaps.

A. Core Standards – Universal Lab Test Code Systems

These are the primary standard vocabularies for laboratory and diagnostic test names and related attributes. They provide the definitive codes and structured descriptors for most tests observed in the dataset.

Dataset / Ontology	Maintainer / Source	Scope & Coverage	Relevant Slot(s) in Test Model	Format / Access	License	URL	How It Maps to Our Data	Notes / Gaps
LOINC (Logical Observation Identifiers Names and Codes) – Latest v2.81 (2025)	Regenstrief Institute & IEEE	Global standard for lab tests and clinical observations; ~100k codes covering virtually all clinical laboratory analytes, panels, and many imaging study names ￼ ￼. Also includes structured parts (Component, Property, Time, System, Method, Scale) for each test.	Component (Analyte name), Property (e.g. substance concentration, enzyme activity), System (sample type e.g. Blood, Urine), Method (e.g. EIA, kit), Scale (Quantitative/Qualitative), Panel definitions. LOINC also provides Units (example UCUM units) and synonyms.	CSV, JSON, & OWL downloads; Searchable via LOINC FHIR API ￼. Biannual releases (Feb/Aug).	Open (free with registration, LOINC License).	loinc.org (Downloads, RELMA mapping tool)	Maps ~80% of lab tests in our data by providing a code for each distinct test (e.g. Glucose in serum, CBC panel, Chest X-ray). We will use LOINC to assign a standard code to each local test name. LOINC’s multi-axial model fills in missing detail: e.g., local “Na+” maps to LOINC “Sodium [Moles/Vol] in Serum/Plasma”, property = substance concentration ￼. Panels like “Lipid Profile” have LOINC panel codes with member tests.	Very high coverage for chemistry, hematology, serology, etc. Gaps: Some local package names (e.g. “Executive Panel”) won’t have direct LOINC codes – those will map to sets of LOINC codes or require custom grouping. Some imaging procedures are included in LOINC (radiology playbook) but coverage is not complete for all modality variations – we may prefer RadLex for detailed imaging terms.
SNOMED CT (Systematized Nomenclature of Medicine – Clinical Terms) – Intl. Edition 2025	SNOMED International	Comprehensive clinical ontology covering lab test concepts, results, diagnoses, procedures, anatomy, organisms and more. Its lab content overlaps with LOINC (has a hierarchy of observable entities including lab tests). Also rich in imaging procedures and clinical findings.	Test names (as concepts in “Observable entity” or “Procedure” hierarchies), Specimen types, Methods, Organisms, Imaging procedures – all hierarchically linked. SNOMED provides a unified ontology to connect test orders, results, and related clinical info.	Distribution as RF2 files (release format); Browser via SNOMED CT browser. Updates every 6 months.	Proprietary – free for members (e.g. PH is not a member as of writing) or under special license (Global Patient Set offers limited free subset).	snomed.org	SNOMED CT can map many items: e.g. “Fecalysis” maps to “Stool examination” concept, imaging like “Chest X-ray” to “Plain chest X-ray”. It also covers services like “Hemodialysis” or nursing fees if needed. SNOMED’s relationships (e.g. test -> method, specimen) could help inference.	License barrier: Not openly downloadable for non-members – we will likely not use SNOMED as a primary source due to this. However, it’s worth knowing for mapping, and if a mapping to SNOMED is needed (for integration with EMR systems), we can use the open Global Patient Set which includes some common lab terms. SNOMED is optional/secondary for us unless licensing issues are resolved.
OMOP Vocabulary (OHDSI Athena)	OHDSI (Observational Health Data Sciences and Informatics)	Consolidated vocabulary for research (OMOP CDM) that includes LOINC, SNOMED CT, RxNorm, etc. with pre-built mappings. In OMOP, each lab test LOINC is an entry mapped to standardized concepts (often SNOMED).	Cross-reference of codes – maps LOINC codes to OMOP concept IDs and often to SNOMED CT or other standards. Essentially a giant lookup linking various terminologies.	Downloadable from Athena in CSV format. Updated periodically.	Partially open: Download is free but requires account; contains SNOMED content (which still requires agreement).	athena.ohdsi.org (select relevant vocabularies)	We will leverage OMOP mainly to obtain ready-made mappings: e.g., LOINC to SNOMED mapping entries, or to confirm if a local test maps to an existing standard concept. It can also validate unit mappings and reference ranges.	OMOP is an aggregator, so it doesn’t add new test definitions beyond LOINC/SNOMED – but it ensures consistency and provides concept relationships (e.g., maps “HbA1c LOINC” to “Glycated hemoglobin measurement” SNOMED concept). Must-have for crosswalks if we plan OHDSI/analytics integration, but if purely mapping to our own system, LOINC (and others listed) suffice.
HL7 FHIR Laboratory ValueSets (US Core, etc.)	HL7 International	Definition of how lab codes are used in FHIR profiles, and curated sets like “Common Lab Orders” and “Common Lab Results” value sets for interoperability. US Core profiles require certain LOINC codes for vital lab results. CDC’s LIVD mappings (for device IVD tests to LOINC) also fall here.	Value sets of LOINC codes for specific contexts (e.g. a list of common tests every system should support), FHIR profiles describing lab observations (Observation.resource structure with code = LOINC, units = UCUM, etc.).	Available via HL7 website and FHIR API. For example, US Core Lab Results ValueSet is published as JSON and expansion.	Open (HL7 standards are freely accessible).	HL7 US Core Lab Obs (and ValueSets within)	This will ensure we’re using the correct LOINC codes and units in a modern context. E.g., we can cross-check that for “Hemoglobin” we use the LOINC that appears in US Core common labs, to maximize interoperability. It also provides guidance on units (UCUM) for each test and helps prioritize which tests are most critical (e.g., a common lab list).	Primarily a quality check/enforcement resource. It does not introduce new codes, but rather confirms our choices. Also includes some panels (e.g. “CBC panel LOINC codes”). We should retrieve the Universal Lab Orders set from LOINC ￼ to see if any test in our data is missing standard mapping (unlikely).
LABO (Clinical LABoratory Ontology)	OpenLHS (France) – Paul Fabry et al.	An ontology focusing on laboratory test prescriptions and results reporting as informational entities ￼. It formalizes lab test concepts (orders, observations) and their components in an ontological framework (OBO Foundry).	Ontology classes for lab tests (likely aligning with LOINC concepts), and relationships for preconditions, documents, panels, etc. Could model the test ordering process.	OWL ontology (available on BioPortal and GitHub) ￼ ￼.	Open (OBO Foundry, CC BY license).	purl.obolibrary.org/obo/labo.owl	LABO can add a semantic layer to our reference: it provides formal definitions (in OWL) of tests, which could help with reasoning (e.g., inferring that certain tests are subclasses of “Clinical chemistry test”). For our data, it might help categorize tests or align with broader concepts (like linking a local “FBS” to the class “glucose test” in ontology).	Coverage is moderate (only ~169 classes ￼); it may not have every test, but as part of OBO it integrates with other ontologies. We will use it to enrich metadata (optional). Gaps include imaging and procedures (LABO is lab-focused). It’s a nice-to-have for ontology-driven projects, but not mandatory for basic mapping.

Priority & Notes: LOINC is the top priority – it will serve as the backbone for lab test standardization (covering most chemistry, hematology, serology, panels, etc.). UCUM (units) is also critical (discussed in Section E). SNOMED CT is very powerful but due to license constraints we will likely omit direct use in our open corpus; instead, we rely on open mappings (OMOP, or Global Patient Set) to get any needed SNOMED mappings. OMOP and HL7/FHIR value sets help ensure our mappings are aligned with international best practices. LABO (and similar ontologies) are for enhancing semantic interoperability – they are lower priority than getting the core coding right.

B. Panels & Profiles – Sources Defining Test Groupings and Batteries

To handle bundled tests (profiles, panels, packages) in our data, we need reference sources that explicitly list the composition of common panels (e.g. CBC components, metabolic panels), as well as catalogs of recommended test lists. These sources help map local panel names to their constituent tests and ensure nothing is missed.

Dataset / Source	Maintainer	Scope & Coverage	Relevant Slot(s)	Format / Access	License	URL	How It Maps to Our Data	Notes / Gaps
LOINC Panels & Forms (LOINC Panel Hierarchy)	Regenstrief (LOINC)	LOINC includes hierarchical definitions for common panels and test batteries. Examples: Basic Metabolic Panel, Complete Blood Count, Liver Function Panel, Lipid profile, Urinalysis panel, etc. Each panel LOINC code has an enumerated list of child LOINC codes (with optional/required flags).	Panel → Components mapping. Provides the structured list of tests in each panel and LOINC codes for each. Also defines order vs observation context for panels.	Provided in LOINC release (Excel/CSV “Groups” file, and panel hierarchies). Also accessible via LOINC’s FHIR API (ValueSet expansion for panel codes).	Open (LOINC license).	loinc.org/downloads (LOINC Panels file)	We will use this to map entries like “LIPID PROFILE” (local) to the 4 component tests (Total Chol, HDL, LDL, Triglycerides) via the LOINC panel code ￼. Similarly “CBC” panel to its parts (RBC, WBC, Hgb, Hct, etc.). This ensures we know exactly which tests are included when a panel is ordered, for deterministic mapping and possibly result expectations.	LOINC’s panel definitions cover most standard profiles found in our data. However, some local packages (e.g. “Executive Panel A”) are hospital-specific and may not exist in LOINC – we will need to manually define those from context (using the item list or hospital documentation). Nonetheless, LOINC can model them if we map each component to LOINC.
UNC i2b2 Common Lab Panels (UNC Health Data Dictionary)	University of North Carolina	A curated set of common lab panels used in the UNC Health system’s i2b2 platform. Panels like Basic Metabolic Panel, CBC, Coagulation, Lipid, etc., grouped for convenient querying ￼ ￼. Focused on high-yield panels (they include tests covering ≥75% of typical orders for that panel) ￼.	Panel compositions and synonyms. Likely provides a list of test names/LOINCs under each panel grouping (not all possible tests, but the most common ones).	HTML documentation (i2b2 web dictionary) ￼. Possibly exportable via API or by direct contact.	Open for reference (web).	dictionary.i2b2.unc.edu	This source gives real-world definitions of panels. For example, it lists which LOINC-coded tests UNC considers part of “Comprehensive Metabolic Panel” or “Urinalysis”. We can cross-check our mapping against it – if our local panel is missing a component relative to the standard, we’ll catch it. It also might reveal synonyms (UNC might call a test slightly differently).	UNC’s list is not exhaustive (it omits rarely-ordered components). But it aligns well with practice and can guide which components to expect. We should treat it as a validation tool and for capturing any nuances (like which differential parameters are part of “CBC + Diff”).
WHO Essential Diagnostics List (EDL) – 3rd edition (2021)	World Health Organization	The WHO EDL is a policy list of essential in vitro diagnostic tests for primary care and laboratories ￼. It covers tests by category: e.g. general tests (glucose, CBC, urine strip), disease-specific tests (HIV, TB, malaria, COVID-19, etc.), and anatomic pathology. Meant for low-resource settings to ensure availability ￼.	List of test names (generic, not coded) categorized by use case and level of care. It ensures we include key tests like those for major diseases (e.g. HbA1c for diabetes, CRP, Xpert MTB/RIF for TB, Dengue NS1, etc.).	Published as PDF and an interactive web list ￼. We can extract the list; it’s not in a structured dataset format publicly (but we can compile from the PDF).	Open access.	WHO EDL site (interactive) and PDF update 2021	We will use the EDL to ensure our reference corpus covers all essential tests – if any appear in our data, they must map to a standard code. For example, EDL includes HbA1c, CD4 count, COVID-19 PCR, etc., which might appear in our dataset (or could in the future). Even if not present, including them in our master list might be prudent for completeness.	The EDL is more of a policy guide, not a coding system. We’ll need to map each EDL test name to LOINC/SNOMED codes ourselves. It may also highlight tests in our data that are not standard practice (if any). Note: it doesn’t cover imaging or procedure codes (only in vitro diagnostics).
NHS National Laboratory Medicine Catalogue (NLMC) (UK)	NHS England (Digital) & Royal College of Pathologists	A comprehensive catalog of pathology tests in the UK NHS, with each test defined and assigned a SNOMED CT concept code ￼. It standardizes test names and units across NHS. Includes profiles (panels) and individual tests across disciplines.	Test definitions and allowable units, specimen, methods. Likely also indicates panel membership and hierarchical relationships (built on SNOMED CT).	Distributed via NHS TRUD (Terminology Reference Data Update) as spreadsheets or database. Requires registration.	Free to NHS users, but SNOMED-bound (license needed for full detail).	isd.digital.nhs.uk (TRUD download)	The NLMC can serve as a reference for test naming conventions and panel definitions in another healthcare system. For example, it might list a “Urea and Electrolytes” profile and its components, or the official name for “Fecalysis” (UK term: “stool routine microscopy”). We can use it to find standardized names for some local tests (if SNOMED codes are known, we map via that).	The NLMC is SNOMED CT–centric, which is a hurdle. However, documentation might be available that we can glean without using SNOMED codes (e.g., PDFs summarizing which tests are in which panel). It’s a robust catalog but not fully open. We will treat it as a supplementary resource (to double-check content and perhaps borrow any test definitions we’re unsure of). Optional due to access issues.
Country/Institutional Test Lists (Philippines & others)	Various (DOH, PhilHealth, Hospitals)	Lists of tests and packages as used in practice, which can shed light on local panel composition and terminology. For example: PhilHealth packages for preventive check-ups (which tests are bundled), DOH standard lab capability lists (for licensed labs), and specific hospital test catalogs (like PGH, NKTI, etc.).	Local panel definitions and synonyms. For instance, what does an “Executive Panel” include? How are tests named locally (e.g., “VDRL” vs “RPR”, “fecalysis” vs “stool exam”)? These sources provide that mapping.	PDF/Website. E.g., public hospitals often publish price lists with test names ￼. The Department of Health licensing requirements list minimum test menus for each lab level (document references). PhilHealth’s case rate descriptions sometimes list included diagnostics.	Publicly available (though not centralized).	e.g. JRRMMC Laboratory Price List (DOH hospital)	We will compile local references to capture Philippine-specific panels: e.g., DOH’s “Basic Diagnostic Package” might include CBC, urinalysis, CXR for certain check-ups. Our dataset’s “ECU” prefix suggests a standardized executive check-up, which likely follows a DOH or hospital-defined test battery. By obtaining these definitions, we can map “ECU – Lipid Profile” to its tests, “Executive Panel A” to its contents, etc.	These sources are fragmented. We’ll likely gather a few key ones: PGH’s test list (which includes combos and local names) ￼, NKTI (via FOI) etc. They may not be in machine-readable format, requiring manual curation. They are nonetheless crucial for filling gaps where international sources don’t specify a grouping or local name.

Priority & Notes: For panels, the LOINC panels file is primary – it directly gives us structured data for most standard profiles (CBC, metabolic panels, etc.). WHO EDL is important to ensure we cover all critical tests, but it’s not structured – treat it as a checklist. UNC i2b2 and NHS NLMC are more for cross-validation and gleaning implied standards (not absolutely required, but very helpful). Philippine-specific lists are essential for locale alignment – since our dataset is from the PH, capturing local package definitions and synonyms will be necessary for 100% mapping (these would be high priority to gather early in the project, even if it means manual effort).

C. Microbiology & Serology – Organisms, Culture & Sensitivity References

Microbiology tests involve identifying organisms and testing antibiotic susceptibilities, while serology involves immunological assays often for infectious agents. To map these, we need resources for organism nomenclature and antibiotic names/codes, as well as any standard codes for micro tests.

Dataset / Resource	Maintainer	Scope & Coverage	Relevant Slot(s)	Format / Access	License	URL	How It Maps to Our Data	Notes / Gaps
NCBI Taxonomy (Organism Database)	NCBI (NIH)	Comprehensive taxonomy of organisms (over 1M species) with a hierarchical classification ￼. Widely used for annotating species in biomedical databases.	Organism names and identifiers. Provides official names and synonyms for bacteria, viruses, fungi, parasites, etc. Each organism gets a TaxID.	Downloadable as text files (names.dmp, nodes.dmp) via NCBI FTP ￼; also accessible via API. Updated continuously.	Public domain (open)	NCBI Taxonomy	For any culture result or organism mention, we use NCBI taxonomy IDs/names. In our test descriptions, organisms aren’t explicitly named, but tests like “AFB, Acid Fast Bacilli stain” or “KOH” imply looking for any of multiple species. When mapping result data, having taxonomy is essential (e.g., mapping “E. coli” to TaxID 562). For our reference corpus, we will include at least the subset of taxonomy relevant to clinical lab (common human pathogens).	NCBI Taxonomy is extremely detailed; we likely need only a slice (all bacteria, viruses of clinical interest). We can filter by known lab organism lists (e.g., those in WHONET or CLSI documents). But it covers everything needed with global acceptance. We should be cautious to map to the correct strain/serotype level as needed (most tests identify at species/genus level).
WHONET Antimicrobial Code List	WHO Collaborating Center for AMR (Brigham & Women’s Hospital)	A standardized list of antibiotics and their codes used for susceptibility testing data. WHONET (AMR surveillance software) defines short codes for each antimicrobial (e.g., AMP for Ampicillin, GEN for Gentamicin, etc.) ￼. Also includes organism groupings and breakpoints (via separate files).	Antibiotic names, abbreviations, classes. This will ensure we use consistent names for drugs in sensitivity panels (and can map to full drug name or ATC code).	Available via WHONET documentation (PDF lists) ￼ and potentially in the WHONET software. May need to manually extract.	Open (free from WHO).	whonet.org (documents section)	Our dataset’s micro tests like “Culture and Sensitivity” don’t list the antibiotics, but when building the reference, we should include the panel of antibiotics typically tested for a given culture. Using WHONET’s list, we’ll incorporate all relevant antibiotics (ensuring our system can represent results like “S. aureus – Oxacillin: Resistant”). The codes help if we need short labels. We can also map these to standard drug codes (e.g. ATC J01 codes or RxNorm).	WHONET focuses on antimicrobial codes; we should cross-map these to an international drug nomenclature. The WHO ATC classification for anti-infectives (J01 codes) ￼ is a good complement – we will likely include ATC as well to categorize antibiotics (e.g., all penicillins under J01C). ATC is open (via WHO’s ATC Index). So, WHONET + ATC gives us both the lab-facing code and a formal classification.
LOINC Microbiology Terms	Regenstrief (LOINC)	LOINC includes many codes for microbiology tests: e.g., “Culture, blood – aerobic”, “Gram stain of sputum”, specific antigen tests, and serology titers. It also has panel codes for susceptibility (e.g., panel of organism isolate with multiple antibiotic results as a single panel code).	Test codes for micro procedures (culture, stains, molecular ID). Panel structure for susceptibilities (some labs use LOINC panel for “antibiogram”). Also LOINC answer lists sometimes reference organism or drug lists (though often using external standards like SNOMED or UCUM for colony count units, etc.).	Included in LOINC release. Query by keywords (e.g., “culture” yields many codes per specimen type).	Open (LOINC license).	Same LOINC link as core.	We will utilize LOINC codes to map tests like “Urine culture” (e.g., LOINC code for “Urine culture” exists) and “Gram stain”. For serologies: LOINC will provide codes for tests like dengue IgM, HIV, HBsAg, etc. This is crucial to maintain consistency with our other lab mappings. For susceptibility results, we may or may not assign separate LOINCs (often results are handled differently), but LOINC has codes for things like “Organism identified” and “Antibiotic X [Susceptibility]”.	Coverage is good for named tests, but not for every local nuance. For example, our data’s “KATO-KATZ for Schisto” might not have a specific LOINC code (it might fall under “Ova and Parasite exam” more generally). We may need to either find the closest LOINC or create a local extension for such specialized parasitology methods. Also, LOINC’s approach to susceptibility is to treat each drug as a separate LOINC test (e.g., “Amikacin [Susceptibility] by MIC”) – we might simply use WHONET codes instead for easier handling, but we’ll have LOINC as reference if needed.
NCBI/GenBank Pathogen Sequencing Data (optional)	NCBI (NIH)	In case of molecular tests for specific genes or strains, NCBI’s genome database can provide reference sequences or identifiers. E.g., if a PCR for COVID-19 is in our data, mapping to a reference (like NCBI accession for the SARS-CoV-2 genome) might be useful for detailed reference.	Pathogen strain references (genome IDs, gene IDs).	FASTA/GenBank data via NCBI.	Public domain.	NCBI Virus (for SARS-CoV-2, etc.)	Not directly needed for test names, but if we want a deterministic corpus that also covers what the test detects (e.g., “Xpert MTB/RIF detects M. tuberculosis complex and rifampin resistance-conferring mutations”), these references could enrich the content. For now, likely out of scope unless we extend into molecular test details.	This is more about content/reference info rather than coding, so it’s truly optional. The main thing is to ensure test names are mapped; linking to pathogen reference sequences is an extra that isn’t required for the mapping task.

Priority & Notes: For micro and serology, the absolute must-have is NCBI Taxonomy (to standardize organism names). Next, WHONET & ATC for antibiotic names – crucial if we handle susceptibilities. LOINC’s micro terms will already be part of our LOINC download (we just need to filter and use them); they ensure tests like cultures and serologies have codes. The combination of these resources covers tests like “AFB smear” (LOINC code exists) and results like “Mycobacterium tuberculosis” (NCBI TaxID and SNOMED code if needed) and drugs like Isoniazid (WHONET code INH, ATC J04AC01). We should also be mindful of answer lists for qualitative serology (e.g. dengue IgM positive/negative – we’ll use standard answers like SNOMED CT concepts for “Reactive” vs “Non-reactive” or LOINC answer lists, though answer standardization is a separate aspect).

D. Diagnostic Imaging & Procedures – Radiology and Beyond

Our dataset includes many imaging studies and some therapeutic or monitoring procedures. To map these, we need standard vocabularies for procedure names, imaging modalities, and related codes. Here are the key sources:

Dataset / Vocabulary	Maintainer	Scope & Coverage	Relevant Slot(s)	Format / Access	License	URL	How It Maps to Our Data	Notes / Gaps
RadLex (Radiology Lexicon)	RSNA (Radiological Society of North America)	Comprehensive lexicon of radiology terms including imaging procedures, anatomy, imaging modalities, findings, etc. RadLex Playbook specifically provides codes for standard radiology exam names (called RIDs or Playbook IDs). E.g., distinct codes for “XR Chest 2 views” vs “XR Chest PA upright”.	Procedure names for imaging (with modality, anatomy, view specified). Also includes modality codes and contrast info. RadLex overlaps with LOINC’s radiology playbook but is more detailed and radiologist-curated.	Download as OWL or spreadsheet via RSNA site. Also browsable.	RadLex is free for use (open to the community).	radlex.org	We will map each imaging entry to a RadLex code where possible. For example, “Chest X-ray PA” – RadLex likely has a term for that specific projection. “MRI prostate multiparametric” – RadLex will have a concept for prostate MRI with multiparametric protocol. Using RadLex ensures consistent naming (we can use the RadLex preferred name in our corpus).	RadLex provides very granular terms. It may be challenging if our descriptions don’t exactly match (we might need to combine RadLex terms for view + body part). However, RadLex Playbook was an attempt to create exam codes (like LOINC) – we should get that subset. Must-have for imaging mapping, complementary to LOINC (which has fewer imaging codes).
DICOM Controlled Terminology (Modality Codes)	DICOM Standards Committee (NEMA)	DICOM defines standardized codes and abbreviations for imaging modalities (e.g., CT, MR, US, CR, DX) and related attributes. It also has codes for body positions and view projections (through defined Context ID lists) ￼ ￼.	Modality (equipment) codes (the two-letter codes like CT, MR, US, etc.), which can fill the “modality” slot of an imaging procedure. Also codes for image orientation (AP, lateral) and other technique parameters, as used in DICOM headers.	Part of DICOM standard (PS 3.16). Available as tables (CSV, XML in standard distribution). Also on HL7 Terminology site ￼.	DICOM standard is free (public domain).	dicom.nema.org (Part 16 contains codes)	We will use modality codes to normalize entries: e.g., label “Chest X-ray” with Modality = “CR” (Computed Radiography) or “DX” (Digital Radiography) as per DICOM. For each imaging test, we capture the modality and ensure it matches one of these standard codes ￼ ￼. These codes might be used in our system’s backend or to interface with PACS.	The modality code alone doesn’t uniquely identify the procedure (body part and technique needed too), but it’s a key attribute. We should also gather DICOM codes for projections if possible (like “AP” or “PA” have codes in DICOM Context Groups). DICOM’s focus is imaging attributes; it doesn’t list “Chest X-ray” as a single concept (that’s why we use RadLex or CPT for the procedure name). So we’ll use DICOM codes in addition to RadLex for a complete representation.
WHO ICHI (Intl. Classification of Health Interventions) – Beta-3 (2023)	WHO (World Health Organization)	A new international standard for procedure codes, covering diagnostic, surgical, public health interventions across all domains ￼ ￼. Uses a structured code with axes for Target (body part), Action, and Means (technique) ￼. Imaging procedures are included (e.g., code for an X-ray of chest, MRI of brain, etc.) as diagnostic interventions.	Procedure coding for diagnostics. Each imaging test can potentially be coded in ICHI (e.g., “Diagnostic imaging of [body part] by [modality]”). Also covers non-imaging like physiologic tests (ECG) and even lab tests, though lab coverage might be high-level.	Published as a Beta release; available through an online browser and PDF reference guide. A formal release with codes is expected.	Expected to be free (when officially released; Beta is accessible online).	WHO ICHI Browser	We can assign an ICHI code to each procedure, to be internationally comparable. For example, an ultrasound of abdomen might have an ICHI code of form “Diagnostic imaging, abdomen, ultrasound”. This gives us a consistent code for use in analytics or reporting (particularly useful if sharing data globally without CPT).	As a beta, ICHI might not perfectly match every nuance (and it’s less granular than CPT in some cases). Also, not all codes are final. We will use it if we want an open international procedure code for each item. It’s a good future-proofing step. Not critical for internal mapping if RadLex and others suffice, but valuable if our corpus aims to be globally interpretable.
FHIR ImagingStudy & Procedure (HL7 FHIR resources)	HL7 International	Not a vocabulary per se, but FHIR defines how to represent imaging studies and procedures in health IT systems. It often expects a coding for the procedure (e.g., using SNOMED CT or LOINC) and includes fields for modality (using DICOM codes) and body site (using SNOMED or FMA codes).	Structure for imaging data – e.g., ImagingStudy resource has a modality list (from DICOM codes) and can carry the procedure code. FHIR’s suggested codes for procedure often default to SNOMED CT or LOINC for imaging.	Specification documentation (profiles for US Core Radiology, etc.). ValueSets in HL7 Terminology.	Free (HL7 standard).	HL7 FHIR ImagingStudy and Procedure resource.	We will align our reference with FHIR expectations: ensure that for each imaging test, we have: a procedure code (from RadLex/LOINC/SNOMED), a modality (DICOM code), and body site (could use SNOMED anatomy or an open anatomy ontology). This way, if our corpus is used in a FHIR context, it will fit naturally.	We might pull the FHIR value sets for imaging procedures if available (e.g., US Core might list some common imaging codes). However, FHIR generally leaves the coding system choice open (just suggests SNOMED or LOINC). So our use of RadLex with DICOM modality is fine; we just document that mapping.
CPT® and HCPCS (Procedural Codes, US)	AMA (CPT) / CMS (HCPCS Level II)	CPT: the dominant US billing codes for procedures (including radiology exams, lab tests, surgeries). HCPCS Level II: codes for ancillary services and non-MD services (includes some diagnostic codes like ambulance, DME, etc.). CPT has detailed codes for each imaging procedure (e.g., separate codes for single view vs multiple view X-rays, with numeric codes).	Billing codes for tests/procedures. This is relevant if we ever need to map to a billing or claims dataset. Each imaging or lab test has a CPT code (lab tests mostly in 80000-series, imaging in 70000-series). HCPCS adds codes for things like new lab tests (PLA codes) and radiopharmaceuticals.	CPT is published as text (manual or electronic files) – not openly available without license. HCPCS Level II is freely downloadable (CMS).	CPT: Proprietary (AMA); HCPCS: open.	AMA CPT site (license required); CMS HCPCS	We will not include CPT codes in our open dataset (due to license) ￼, but we will design our reference such that it could be mapped to CPT if needed. For instance, we know “Chest X-ray 2 views” corresponds to CPT 71046. We will keep a placeholder or mapping table (outside of the publicly released corpus) for such links. HCPCS codes (e.g., G codes for certain labs) can be included for completeness as they’re public.	CPT is the one major standard we cannot directly use in an open project. We’ll note its codes only as needed for internal use. For open release, we might rely on ICHI or SNOMED as the procedure code. HCPCS Level II might not directly apply to most items (except possibly things like ambulance EEG or specific drug admin which are minimal in our data).

Priority & Notes: For imaging, RadLex and DICOM codes are the top priorities – together they cover the exam naming and modality. We should get RadLex Playbook (which might already map to DICOM modality tags). ICHI is a strong secondary resource for an open procedure code standard (especially if we want to avoid CPT/SNOMED). It’s worth including for future-proofing, though we could proceed without it initially. FHIR alignment is more about design; we should ensure we capture modality and body site attributes. We will also utilize an anatomy ontology for body parts if needed (e.g., FMA or Uberon for “left ankle” vs “right ankle”). This wasn’t listed in the prompt explicitly, but likely falls under supporting ontologies – we will mention in Auxiliary Ontologies (Section H).

CPT is acknowledged but will be excluded from the open corpus; we just remain aware of it.

E. Units & Measurements – Standard Units and Properties

A deterministic lab reference must handle units of measure and quantitative values consistently. The primary standard for units is UCUM, and we also need to know the “property” of a measurement (mass vs substance concentration, etc.) which ties into units. Resources:

Dataset / Standard	Maintainer	Scope & Coverage	Relevant Slot(s)	Format / Access	License	URL	How It Maps to Our Data	Notes / Gaps
UCUM (Unified Code for Units of Measure)	UCUM Organization (Regenstrief & HL7)	The universal code system for units used in healthcare and science. Defines symbols for all units (SI units, conventional units, and composites) ￼. E.g., mg/dL is represented as mg/dL in UCUM, and it has a standardized meaning.	Units of measure for test results. Each quantitative test in LOINC has recommended UCUM units. UCUM ensures that “mmol/L” vs “mMol/L” are recognized as the same, etc. It also encodes conversion factors between units (implicitly by rigorous definitions).	Published as a specification (PDF) and an XML file of unit definitions. Many implementations available (Java, etc.) for validation.	Open (CC BY-SA 3.0)	ucum.org	We will use UCUM codes for all units in our dataset. For example, local data might mention “mg/dL” or “IU/L” – we verify those against UCUM. If a local unit is written oddly (like “mg%”), we map it to UCUM standard (mg/dL). We’ll include an authoritative list of units that occur in our data (gleaned from reference ranges or typical units for each test). UCUM also allows us to do automatic conversions if needed.	Must-have for any quantitative lab data. There’s essentially no gap – UCUM covers all likely units (including medical ones like “cells/µL”, “IU”, “M.Eq” etc). We might need to enforce usage (some local terms like “secs” for seconds will be mapped to UCUM s). We should also include any compound units (e.g., “mg/g creatinine” for urine ratios) as UCUM.
LOINC Property and Units mappings	Regenstrief (LOINC)	Within LOINC’s dataset, each test code has an associated Property (e.g. MCnc = Mass Concentration, SCnc = Substance Concentration, ACnc = Arbitrary Concentration, etc.) and Example Units. The LOINC Part database contains these properties as codified attributes.	Property type of each measurement (helps interpret the meaning of the value and what units are applicable). Also suggested units (e.g., glucose in mg/dL vs mmol/L).	In LOINC release tables (e.g., Loinc.csv has property and units fields).	Open (LOINC).	LOINC download	We will extract from LOINC a mapping of LOINC code -> property & units. This allows building a rule base: if a test is mapped to LOINC X with property “SCnc” (substance concentration) and example unit “mmol/L”, but our local data uses “mg/dL”, we know we’re dealing with mass vs substance units and can infer conversion or at least flag the difference. Essentially, LOINC’s property guides the unit usage.	No additional license needed since we have LOINC. One challenge: if a local test isn’t in LOINC, we might need to assign a property ourselves. We can use existing property definitions from LOINC (they have a finite list of properties). Ensuring each quantitative test has a property (e.g., enzyme measurements are catalytic activity (ACnc), blood cell counts are number concentration, etc.) will make our corpus consistent.
QUDT Ontology (Quantities, Units, Dimensions and Data Types)	QUDT.org (open community)	An ontology that models physical quantities and units. It includes classes for QuantityKinds (like Mass Concentration, Length, Pressure) and links them to units (with conversion factors). Essentially an RDF/OWL version of unit conversions and dimensional analysis.	Dimension and quantity type for each unit. For example, QUDT knows mg/dL is a type of MassConcentration and can convert it to e.g. kg/m³. It provides a formal semantic layer to reason about units and detect mismatches.	RDF/OWL files, also a SPARQL endpoint.	Open (Apache 2.0 License).	qudt.org	We will incorporate QUDT or its data in our knowledge base to support inference: e.g., if a result is in mmol/L and another in mg/dL, QUDT can help compute conversion if molar mass is known (though that part might require chemical info). At least, QUDT will let us confirm that mmHg and kPa are both Pressure units, etc. In context, if a local unit is non-standard, QUDT can help identify it.	This is more for advanced usage. For initial deterministic mapping, we might not need full QUDT integration, but having it ensures we can do unit consistency checks. An alternative simpler approach: use LOINC’s “conversion factor” data where available (LOINC sometimes gives SI conversion factors in its Companion Guide). But QUDT is a comprehensive solution beyond healthcare (so it covers any odd units too).
HL7 V2 / FHIR Unit ValueSets	HL7 International	HL7 has historically recommended units via tables (HL7 v2 had a UCUM-based table, and FHIR uses UCUM as a required standard for Observation units). There are example ValueSets of common units in some IGs.	Common units list (mostly for UI pick-lists). Possibly not needed explicitly, since UCUM covers all, but it can be useful to see a curated subset.	Documentation, or FHIR IG (like UCUM codes for UCUM Vital Signs ValueSet, etc.)	Free	terminology.hl7.org	This is minor – essentially we’ll ensure our units align with HL7’s expectations (which they will if we use UCUM). We might use a list to restrict to meaningful units (e.g., for temperature use “Cel” not “Celsius” in text).	No major gaps. It’s mostly a sanity check. Our main focus will be on UCUM itself.

Priority & Notes: UCUM is mandatory – we will integrate it at the start so all numerical data is annotated with UCUM codes. The LOINC property info is extremely useful; it will come along with LOINC and we should not ignore it, as it informs both unit selection and any calculations. QUDT is a nice enhancement for ensuring rigorous unit handling – it’s optional but recommended if we plan on doing any automated unit conversion or reasoning (e.g., checking that reported units match expected property). Since QUDT is open, including it has no downside except complexity.

In summary, we’ll first standardize all units via UCUM and attach a “property” to each test (mass concentration, enzyme activity, etc.) using LOINC or manual classification. This will make our reference “deterministic” in terms of understanding what a numeric result means physically.

F. Cross-Mapping Resources – Linking Code Systems for Interoperability

To enhance the deterministic mapping, we might need to cross-link different standard vocabularies, ensuring our corpus can translate between them if needed. The following resources provide mappings between major code systems (with emphasis on open or at least accessible mappings):

Mapping Dataset	Maintainer	Source & Target	Format / Access	License	URL	Usage in Our Project	Notes
LOINC – SNOMED CT Mapping (Lab observables)	Regenstrief & SNOMED Int. (cooperative project)	Maps many LOINC terms to equivalent or broader SNOMED CT concepts in the SNOMED CT Observables hierarchy ￼. For example, a LOINC code for a test might map to a SNOMED code for that test. Also includes linkage of LOINC Parts to SNOMED concepts (e.g., the LOINC component “Glucose” part mapped to SNOMED substance “Glucose”).	Was released as an RF2 refset to SNOMED CT members. Not openly downloadable without SNOMED license.	License required (SNOMED).	loinc.org/snomed (announcement)	We won’t embed SNOMED codes in our public corpus, but this mapping is useful internally. It allows validation that our LOINC-coded tests align with SNOMED concepts (especially if later integration into an EHR that uses SNOMED is needed). If Global Patient Set (GPS) includes some of these mappings, we might use those (GPS is free).	Not open unfortunately. We will rely on OMOP or UMLS as indirect open sources. If PH healthcare uses GPS SNOMED (a limited free set), we might extract lab concepts from GPS. Otherwise, this mapping is a lower priority due to accessibility.
OMOP Concept Relationships (LOINC – SNOMED)	OHDSI (Athena)	Within the OMOP vocabulary, LOINC lab test concepts often have a mapped standard concept which might be a SNOMED CT concept (or the LOINC itself is marked as standard). OMOP provides tables like concept_relationship and concept_mapping that link codes. E.g., LOINC X might have a relationship “Mapped to” SNOMED Y.	Athena download (CSV tables).	Open for research use (registration needed).	athena.ohdsi.org	We will likely use this as an open surrogate for the LOINC-SNOMED map. By loading the OMOP concept tables filtered for LOINC and SNOMED, we can get many mappings. This lets us include, in our corpus, a “SNOMED CT (for reference)” column (without distributing SNOMED descriptions). It’s an enrichment step.	OMOP’s mapping may not cover every test and might occasionally pick a concept that isn’t a perfect match (because SNOMED’s lab coverage is tricky). But it’s a solid start. We must ensure not to violate SNOMED license – likely we can include SNOMED numeric IDs from GPS or OMOP since those are derivative works; however, we won’t include descriptions without license.
LOINC – OMOP Vocabulary Mapping	OHDSI	This is effectively just the OMOP concept list where each LOINC code is an entry with an OMOP concept ID. It tells us if the LOINC code is “Standard” or mapped to another concept.	Athena CSV.	Open (with registration).	Athena – LOINC	Using this, we ensure every LOINC we use is recognized in OMOP. For our purposes, it means if researchers use our corpus, they can easily map to OMOP analytics. The concept IDs provide a stable key.	Most LOINC codes are themselves standard in OMOP. This is straightforward but part of the ETL if needed. Not critical for the mapping itself, more for downstream compatibility.
FHIR Observation to LOINC (Example mappings)	HL7 / Regenstrief	Sometimes HL7 publishes example mappings of certain profiles to LOINC. Also, CDC’s LIVD initiative provides mapping from device-specific test codes to LOINC. While not exactly code-to-code, it is mapping from local codes (instruments) to LOINC.	Various (LIVD is often CSV or Excel provided by manufacturers; HL7 examples in IGs).	Mixed (LIVD data from vendors might be open for COVID, etc.).	CDC LIVD	Not a general need for our internal mapping, but if any of our tests are known by device names (e.g., some COVID rapid tests), LIVD could confirm the correct LOINC. This is a niche case.	We can consider this optional. LIVD is more for operational lab mapping rather than building a reference ontology.
UMLS Metathesaurus	U.S. NLM	Aggregates LOINC, SNOMED CT, ICD, etc., and provides mappings and synonyms. For example, it connects LOINC codes to other vocabularies and provides synonym rings.	Mappings between many codes; also synonyms in multiple languages.	Download (RRF files) – requires UMLS license (free, but requires agreement; SNOMED content included requires that license).	Semi-open (free for research with registration)	uts.nlm.nih.gov	UMLS could help find additional synonyms or lay terms for tests (like connecting “fecalysis” to concepts). It’s also another source of LOINC-SNOMED connections via the concept unique identifiers (CUIs). We may use it to double-check any mapping uncertainties.

Priority & Notes: For cross-mapping, since our aim is an open deterministic corpus, we lean on OMOP as the primary bridge (because it’s accessible and contains mapping info). We will extract LOINC to SNOMED mappings from OMOP. Direct LOINC-SNOMED map from Regenstrief is ideal but not open. UMLS is a possibility if needed. These mappings are not needed for the core function of our reference (which is to map local tests to a chosen standard like LOINC), but they future-proof our work and increase its utility (e.g., enabling users to get SNOMED codes for tests if they have a SNOMED license, or to join with OMOP databases).

Another cross-map not explicitly listed but useful: LOINC to ICD-10 for lab tests (rare, but some tests correspond to diagnostic classifications, e.g., newborn screening tests to ICD codes for disorders). This is out-of-scope perhaps.

We will focus on LOINC-centric mapping, but record these cross-links in a non-public part of the corpus or in documentation so that the corpus can be extended/interfaced with other systems.

G. Locale-Specific References (Philippines & Regional)

Because the dataset is from the Philippines, capturing local terminologies and context is essential. These sources provide the local names, abbreviations, and standards in the Philippine setting:

Resource	Maintainer	Scope & Details	Format / Access	License	URL	How It Helps Map Local Data	Notes
DOH Standard Lab Service Capability Lists	Department of Health (PH)	The DOH issues guidelines (Administrative Orders) for clinical laboratory licensing. These often list the minimum tests a lab must offer at each level (primary, secondary, tertiary) ￼. They cover test names in local usage (English, sometimes Filipino terms).	PDF circulars, e.g., AO 2007-0027, AO 2021-0037 (licensing regs) ￼. Possibly tabulated in annexes.	Public domain (gov’t issuance).	DOH website / eLibrary (for AO documents)	These lists confirm the common tests and names in the local context. For example, it explicitly mentions tests like “Stool examination (Fecalysis)”, “Hematocrit”, etc., thereby linking the local term to a standard understanding. We will use it to ensure no local routine test is missing from our corpus and to normalize synonyms (it often lists both local and standard name).	Likely does not include advanced tests (just routine ones), but those advanced ones we cover via LOINC anyway. It’s a baseline.
PhilHealth Benefit Package Test Lists	PhilHealth (Philippine Health Insurance Corp)	PhilHealth’s case rate packages and specialized benefit packages sometimes list included diagnostic tests. E.g., the Diabetes package might include “FBS, HbA1c”, or maternity package includes “urinalysis, CBC”. There was a COVID testing benefit that defined what tests are covered.	PDFs on PhilHealth website (circulars for packages) or the searchable Case Rates portal ￼ (though that is more ICD-based).	Public	PhilHealth Circulars	Using these, we ensure that if an entry like “OPD laboratory package” exists, we know which tests that entails. Also, if local tests are abbreviated weirdly in claims, these docs might reflect that (not as reliably as hospital data, but still useful).	Minor role – mostly to double-check package contents. We should prioritize hospital sources first.
Public Hospital Laboratory Catalogs (e.g., PGH, RITM, NKTI)	Philippine General Hospital (UP Manila), Research Institute for Tropical Medicine, National Kidney & Transplant Institute, etc.	These are often price lists or service guides enumerating tests offered, sometimes with local names and brief descriptions. For instance, JRRMMC (a DOH hospital) list shows “Wet Smear”, “Malaria Smear”, etc. ￼; PGH’s list might highlight packages like “Executive Panel”. RITM, being a reference lab, has a test catalog with specific infectious disease tests (like dengue PCR, etc.).	PDF or web pages. JRRMMC list (we have), PGH’s site has a section for Rates & Fees ￼, RITM might have a handbook. FOI requests have been used to get NKTI’s lab price list ￼.	Public (if published openly; FOI data is public domain).	e.g., JRRMMC Lab Price PDF	These are gold mines for synonym mapping. We directly see how a test is referred to locally and can map it to the standard name. E.g., “HBSAg” vs “HBsAg”, “SCOT/SGOT” local usage for AST. The lists also reveal any unique local tests or panels (like “NS1 Antigen (Dengue)” clearly spelled out). We will parse these lists to build a table of local alias -> standard.	We should compile a consolidated list from at least one major general hospital (PGH or JRRMMC) and one specialty/referral (RITM or NKTI) to cover general and special tests. Potential gap: private labs (Hi-Precision, etc.) sometimes use slight variations, but likely similar. The public sources suffice for coverage.
Local Terminology (Common Abbreviations)	N/A (colloquial)	Certain shorthand are ubiquitous in the Philippines: “UTZ” for ultrasound, “CREA” for creatinine, “Na/K” for electrolytes, “C/XR” for chest X-ray, etc. Some of these can be gleaned from charting practices or training materials.	N/A (to be manually collated)	N/A	(We will compile ourselves)	We will maintain a dictionary of these abbreviations to assist mapping. Many we’ve seen in the data already (like UTZ, ECU). If new ones appear (e.g., “HBSAg” vs “HBsAg”, or “CEA” spelled out vs abbreviation), we add them.	This is an informal resource but important for a deterministic parser to recognize synonyms. Might incorporate some from UMLS if available (though UMLS likely has “UTZ” in Filipino context? Unlikely). Mostly based on domain knowledge.

| Language Translation (if needed) | e.g., UP Medical Dictionary | While most tests are in English abbreviations, occasionally Filipino terms might appear (though rare for lab test names). If needed, a medical dictionary or translation of terms (e.g., “Dugo” for blood) could be used. | – | – | – | Probably not needed since lab tests names are English. If any patient instruction appears (like “pag-aayuno” for fasting), we’d handle that manually. | – |

Priority & Notes: The hospital lab catalogs and DOH lists are top priority to gather early, since they directly address the local name mapping which no international source will cover. We have one (JRRMMC) and should get PGH or similar for cross-check. These will address virtually all local naming quirks.

PhilHealth and others are lower priority; they won’t introduce new test names, just group them. Useful as a completeness check but not critical.

One more specific item: in PH, some tests might have different reference values or units (like glucose in mmol/L vs mg/dL depending on convention; in PH it’s usually mg/dL, which matches US, so okay). But things like “mmol/L” might appear if a machine was set differently. Our unit mapping covers that.

We should also be aware of local reference range context – not exactly vocabulary, but our corpus might want to capture typical reference ranges (which could be gleaned from local sources). That’s an enrichment beyond mapping names – optional.

H. Auxiliary Ontologies & Hierarchies – Supporting Knowledge (Specimen, Methods, Anatomy, etc.)

These resources provide background ontologies that help structure the information around lab tests and procedures, enabling inference and consistent categorization:

Ontology / Resource	Maintainer	Scope & Purpose	Format	License	URL	Use for Our Corpus	Notes
OBI (Ontology for Biomedical Investigations)	OBO Foundry community (open project)	Broad ontology covering investigations, assays, protocols, materials. It includes terms for assay methods (e.g., ELISA, PCR), specimen collection processes, and data types ￼ ￼. Provides a framework to represent the entire testing process.	OWL ontology	Open (CC BY 3.0)	obi-ontology.org	We will use OBI classes to tag the type of test or method. E.g., mark that LOINC “HIV ELISA” is a subclass of OBI’s “ELISA assay”, or that “CBC” is a type of “hematology assay”. OBI also has terms for instruments and processes (like “spectrophotometry” or “PCR amplification”), which can enrich method data.	OBI is large; we’ll cherry-pick relevant parts (assay types, specimen-related terms). It aligns with our need to infer things (e.g., if a test method is EIA, we know it’s a kind of immunoassay). OBI also integrates with BFO (Basic Formal Ontology) for high-level consistency.
SNOMED CT Hierarchies (Specimen, Method)	SNOMED Int.	SNOMED has rich sub-hierarchies: e.g., Specimen (with all types of specimens: serum, plasma, urine, CSF, swab, etc.), Procedure method (e.g., radiography, ultrasound, immunoassay, PCR).	RF2 (within SNOMED, if licensed).	Restricted (SNOMED license)	SNOMED browser (if available)	We won’t include SNOMED content openly, but as a design guide: we ensure that each test’s specimen corresponds to a standard concept (we can use SNOMED codes internally or map to an open analog). Similarly, test methods we’ve mostly covered via OBI, but we can cross-map OBI to SNOMED if needed for validation.	We will likely replace direct SNOMED usage with open equivalents (see below: HL7 specimen codes, Uberon, etc. for anatomy). SNOMED is comprehensive, but given license issues, it’s mainly a blueprint we mirror with open sources.
HL7 V2 Specimen Codes (HL7 Table 0070 & 0487)	HL7	A list of specimen type codes historically used in HL7 messaging. E.g., code “BLD” for blood, “SER” for serum, “PLAS” for plasma, “UR” for urine, etc. It’s not exhaustive but covers common ones in 3-letter codes.	Table in HL7 v2 standard (in chapter on Orders/Obs).	Open (HL7)	HL7 V2.8 Std (for context)	We will use this to double-check that our specimen nomenclature is consistent. For instance, our dataset might say “SWAB” ￼ – HL7 code for unspecified swab is maybe “SWB”. We can maintain a map of HL7 code to specimen name to align with any systems using HL7 v2.	It’s a bit dated and limited (doesn’t distinguish all types of swabs, etc.), but since it’s free, we can include it as a reference in our documentation. SNOMED is better for specimen detail, but we’ll rely on HL7 for open standard terms where possible.
Uberon / FMA (Anatomy Ontologies)	OBO Foundry (Uberon), and Univ. of Washington (FMA)	Uberon is an integrated cross-species anatomy ontology that includes human anatomy. FMA (Foundational Model of Anatomy) is a very detailed human anatomy ontology. These provide identifiers for body parts and structures.	OWL ontologies	Open (Uberon CC-BY, FMA free for use)	uberon.github.io	For imaging, when specifying body part examined (e.g., “Chest” in Chest X-ray), we can use an anatomy ontology ID (Uberon: chest = thorax, etc.). Similarly, for “left/right” distinctions, these ontologies have ways to express laterality (Uberon has classes for left/right organs or we use a qualifier for laterality). Using an anatomy ontology ensures clarity in what area a test covers (e.g., “appendix ultrasound” target = Uberon: appendix).	We likely don’t need the entire anatomy ontology; just the parts that appear in our tests. Uberon would be easier to integrate since it’s OBO and broad. We must be careful to pick the correct terms (some slight naming differences – e.g., “Lower extremity” might need combining concepts). However, including anatomy codes will significantly enhance the semantic completeness of our corpus.
BFO & other upper ontologies	IFOMIS etc. (for BFO)	Basic Formal Ontology (BFO) is an upper ontology that OBI and others use. Not directly about lab, but ensures consistent top-level categories (Material Entity vs Process etc.).	OWL	Open	N/A (part of OBI import)	We won’t directly deal with BFO in mapping tests, but since OBI and some ontologies we use depend on it, we include it indirectly. It helps with inference if needed (e.g., distinguishing an observation (information artifact) from the actual analyte (material entity)).	This is behind-the-scenes. No direct action needed except to import if we load OBI in an ontology-aware system.
Inference Rules (custom)	N/A (we will create)	Not an external dataset, but we will formalize rules like: If unit is X and property is Y, then conversion factor is Z; If test name contains “fasting”, add property:fasting = true; If “75g OGTT”, link to concept of glucose challenge dose. We derive these from domain knowledge and above resources (e.g., OGTT 75g challenge is described in clinical guidelines).	Rule scripts or ontology SWRL, etc.	N/A	N/A	We will incorporate these rules into our system for deterministic inference. They ensure completeness. For example, using UCUM/QUDT we infer mass vs molar units; using OBI we infer that ELISA method implies the property is “presence/absence or concentration via immunoassay”; using HL7 specimen codes we infer default specimen if not stated (e.g., assume serum for chemistry tests unless name says urine).	These rules will be documented (perhaps in the narrative of our corpus documentation rather than a table). They are essential glue for determinations that aren’t one-to-one mappings but logical conclusions. We’ll maintain them as part of our knowledge base rather than a separate dataset.

Priority & Notes: Among auxiliaries, OBI and an anatomy ontology stand out as very useful to capture method and anatomy in a structured way (since we chose not to use SNOMED directly for those). Uberon is fairly straightforward to use for anatomy and is open. OBI is a bit heavy but gives us a rich set of method classes.

HL7 specimen codes are a quick win to list – not critical if we have our own designations, but since it’s standard and easy, we’ll include them (maybe as a reference table in our corpus documentation mapping each specimen to HL7 code and SNOMED code if we have).

We consider these supporting ontologies as optional for initial mapping (one can map tests without them), but they become important when we want deterministic reasoning – e.g., answering “is this test measuring a substance or a mass?” or grouping tests by specimen or method automatically.

Thus, we will integrate these mostly in the backend of our reference data model rather than as separate deliverables to end-users, except where they directly help mapping (like using a code for specimen in our data fields).

I. Inference and Rule Support – Structured Knowledge for Derivation

To achieve a truly deterministic and smart reference, we need sources (or encoded knowledge) that allow us to infer implicit details from the data, such as deducing a test’s property from its units, or a procedure’s context from its name. Many of these are not standalone datasets but rather rules derived from standards and domain knowledge. We list them here for completeness:

Knowledge Source / Rule Base	Description & Source	How We’ll Use It	Example
Units-to-Property Mapping Rules	Derived from unit definitions and LOINC conventions. For many units, the kind of quantity is implied. E.g., “%” implies a proportion (LOINC property = NFr (Number Fraction) or similar), “mmHg” implies pressure, “mEq/L” implies substance concentration. We can use UCUM’s dimensional analysis (via QUDT) plus a curated table for ambiguous cases.	When we encounter a test with a unit but no known property, we infer the likely property. This ensures even a non-LOINC local test gets classified (e.g., “erythrocyte sedimentation rate (mm/hr)” – unit mm/hour implies length/time, which in LOINC is a rate property).	Example: Unit “IU/mL” – our rule knows that “IU” is arbitrary unit usually for mass or substance but in context of per volume, treat as Substance Concentration. So an unmapped test “ASO (IU/mL)” we tag property = SCnc (substance concentration).
Method Inference from Keywords	Derived from lab methodology references and OBI ontology. Certain keywords in test names indicate method: “rapid” often implies immunochromatography, “ELISA” or kit names imply immunoassay, “PCR” implies nucleic acid amplification method, “culture” implies microbiological culture method, etc.	If the local test name doesn’t explicitly state the method but contains clues, we assign a standard method. We also use default methods for certain test types (e.g., blood counts -> automated hematology analyzer). This can be stored as a map (keyword -> OBI method class).	Example: “Dengue Duo (Rapid)” – we infer method = immunoassay (lateral flow). “GeneXpert MTB/RIF” – infer method = PCR (automated). “Manual differential count” – method = manual microscopy. These method tags might not appear in LOINC name fully, so we add them for clarity.
Default Specimen Assumptions	Derived from lab practice and LOINC hierarchy. Many test names omit the specimen when it’s obvious. If not stated, we assume a default: e.g., chemistry tests are on blood (serum/plasma), unless “urine” or other is mentioned. Hematology is blood by default (unless it says CSF cell count, etc.). Serologies typically serum.	We will encode these assumptions so that if a local description lacks a specimen, we still assign one. LOINC often uses “Ser/Plas” as a system for those; we can mimic that.	Example: “Magnesium” with no specimen given – assume serum/plasma. “Glucose” with no spec and context outpatient – assume blood (plasma) if it’s a lab test (as opposed to fingerstick, which would still be blood anyway). We document these rules so they’re deterministic. If the context suggests otherwise (say we find the test under a urine section in a bill), we’d override accordingly.
Temporal context and challenge	Derived from clinical protocols (ADA for OGTT, etc.) and LOINC Challenge part. Recognizing “fasting”, “post-prandial”, “2HR”, “75g OGTT” phrases. We map these to structured concepts: e.g., “fasting = patient fasted 8-12 hours”, “75g OGTT 2hr = glucose challenge with 75g anhydrous glucose, sample drawn 2 hours after ingestion”. LOINC has “Challenge” field for this (like “75G GLU 2H” in the code name).	We will create a reference of common challenge protocols and assign them to tests as needed. This ensures that, e.g., “RBS” vs “FBS” are distinguished (Random Blood Sugar vs Fasting Blood Sugar), and OGTT timings are properly annotated.	Example: We see “OGTT, 75g 2 HR” in data – we annotate it with: challenge = 75 gram glucose, timing = 2 hours post dose. If only “FBS” is given, we mark specimen condition = fasting. This allows consistent interpretation or conversion (like one could calculate a glucose tolerance curve if multiple points given).
Clinical Logic Mappings	From medical logic modules or guidelines. Some tests imply subsequent tests or related concepts. E.g., “Type & Screen” implies ABO/Rh + antibody screen. “Direct Coombs (DAT)” implies testing for IgG on RBC. While not needed for coding, we might note these relationships.	Mostly documentation – ensure our corpus notes that certain items are part of a workflow. Could be useful for mapping an order set: e.g., an order of “Type & Crossmatch” covers multiple procedures.	Example: If dataset had “Crossmatching – Packed RBC”, we map to LOINC for crossmatch test, but also note that ABO/Rh is prerequisite. This might be beyond our immediate scope but is a consideration for a fully deterministic understanding of lab orders.
Reference Range Inference	From physiology and units. If we know the analyte and unit, sometimes we can infer the ballpark reference range (e.g., K in mmol/L ~ 3.5-5.0). Not exactly needed for mapping, but part of understanding. Some open datasets of normal ranges exist per test.	Optional: we might include a field for “typical reference range (adult)” for each quantitative test, drawn from e.g. WHO or local sources. It’s not a vocabulary, but a reference attribute.	This could help flag unit mistakes (e.g., if a value doesn’t fit the normal range in that unit, maybe the unit is wrong). However, it’s more of a quality control aspect than mapping – likely out-of-scope for initial build.

Priority & Notes: These inference rules are not external datasets one can download; they are internal knowledge that we will codify based on the above resources and domain expertise. We list them to acknowledge that beyond pure code mapping, a deterministic system needs these rules. We will implement or document them accordingly. The most important for initial mapping are the units-property link and specimen defaults (to fill in missing info, which happens often in billing descriptors).

The others (challenge, method inference) are also high yield given our dataset content (many tests with “fasting” or “rapid” flags). We should incorporate those from the start as well, since they directly affect test identification (e.g., FBS vs RBS are different LOINC codes, distinguished by challenge).

⸻

Coverage Gaps and Plan

After assembling this collation of sources, we should consider if any observed cluster in our dataset still lacks coverage:
	•	Rare or local-only tests: Our dataset might have a few entries that are unique or uncommon (e.g., “Lacrivisc (per use)” – possibly a ophthalmology test/procedure). For such items, no standard code might exist. In those cases, we may need to create a local extension code. The plan would be to use the above resources to define it as best as possible (e.g., describe it, map to closest ontology classes) and flag it as an extension.
	•	Non-lab items: Nursing services, room fees, etc., which appear under LaboratoryAndDiagnostic in the billing. Those are out of scope of LOINC. We either exclude them from the corpus or map them to a procedure code if appropriate (e.g., “Hemodialysis facility fee” might map to a health service code). Since our focus is lab/diagnostic, we likely exclude or separately list these as unmapped.
	•	Traditional medicine tests: Not present in sample, but if there were (like herbal lab tests or such), would be gap (not expected here).
	•	Locale language: Our sources assume English; since the Philippines uses English for medical terms, that’s fine. If we had to cover another language (not required now), we’d include translations (like LOINC has Chinese, etc., but not needed for PH context).

Must-get First vs Optional:

Must-get immediately:
	•	LOINC (full download) and its accessory files (panels, units) – central to everything.
	•	UCUM specification – small but vital.
	•	NCBI Taxonomy (can download subset later, but at least have the ability to reference common organisms).
	•	RadLex Playbook – to map all imaging.
	•	Local PH lab catalogs (at least one or two) – to resolve local terms.
	•	HL7/WHONET antibiotic list – because culture & sensitivity is common, need antibiotic standard names.

High priority (soon after):
	•	OMOP vocab mapping – to get crosslinks (not critical for initial mapping, but good to have).
	•	OBI and Uberon – to start adding method and anatomy details for completeness.
	•	WHO EDL – to verify completeness (especially ensure tests like “HIV viral load” or “CD4 count” if present are mapped – they often show up in EDL).
	•	ICHI – if we want an open procedure code for imaging from the get-go, otherwise can wait.
	•	HL7 specimen codes – quick to integrate while doing specimen mapping.

Optional/enrichment:
	•	SNOMED CT mappings – only if there’s a later need (could skip due to complexity).
	•	UMLS – not needed unless we hit a terminology snag.
	•	Reference ranges – can be left for a later phase or documentation.
	•	Additional ontologies like LABO – nice academically, but our core functionality doesn’t depend on it.

Finally, the versioning and access: we will ensure to note the version of each dataset we use (as done in table where known, e.g., LOINC v2.81, SNOMED 2025 release, etc.). We will maintain the raw files or URLs for reproducibility.

In conclusion, by collecting all the above sources and integrating them, we will build a deterministic reference corpus that can take any entry from esoa_prepared_labs.csv and map it to:
	•	a standardized test/procedure code (LOINC, RadLex, etc.),
	•	with standardized units (UCUM),
	•	standardized specimen and method (from ontologies),
	•	plus linkages to related codes (SNOMED, OMOP) for interoperability,
	•	and handle local phrasing via a curated synonyms table.

This guide serves as the roadmap to fetch and utilize each piece of that puzzle.